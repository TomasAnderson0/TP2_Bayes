---
title: "Informe_Met-Has"
format: pdf
editor: visual
---

La estadística bayesiana se usa para poder dar respuestas a incertidumbres sobre parámetros que afectan a distintas situaciones. Se usan dos fuentes de información para ello, la primera es lo que uno cree conocer sobre los parámetros previamente al realizar un experimento, es decir, la información a *priori*, y la segunda, los resultados que obtiene al realizarlo, que se lo denomina como la *verosimilitud*. Juntando estas informaciones se obtiene lo que se conoce como la distribución a *posteriori* del o los parámetros. Pero para poder encontrar respuesta al desconocimiento sobre el tema se debe poder sacar muestras de la distribución a *posteriori*. Para realizar esto, una de las técnicas que se pueden utilizar es Metropolis-Hasting.

## Metropolis-Hasting

Este método consiste en una cadena de Markov que, a grandes rasgos, recorre los distintos valores de una distribución de probabilidad generando un secuencia de valores posibles $x$ de dicha distribución $x(1),x(2),…,x(S)$, donde para obtener $x(i+1)$ usamos $x(i)$. De esta manera se quiere que el conjunto de los valores simulados se aproximen lo máximo posible a una muestra real de la distribución.

Esta técnica funciona de la siguiente manera:

1.  En la iteración i estamos en el valor $x(i)$
2.  En función del valor actual $x(i)=x$, proponemos un nuevo valor $x′$ en función de $q(x′∣x)$ siendo q la distribución de salto que uno debe proponer, que sera la que presente los puntos de salto posibles.
3.  Decidimos si vamos a la nueva ubicación $x(i+1)=x′$ o si nos quedamos en $x(i+1)=x$:
    i.  Calcular la probabilidad de salto:
        -   $α_{θ→θ′} = min(1,f(x′)f(x))$
    ii. Pasar a $x′$ con probabilidad $α_{x→x′}$:

$x^{(i+1)} =
\begin{cases}
x' \text{ con probabilidad } α_{θ→θ′}\\
x \text{  con probabilidad } α_{θ→θ′}
\end{cases}$
